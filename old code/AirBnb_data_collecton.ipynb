{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Using cached selenium-4.26.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Using cached trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Using cached trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Collecting typing_extensions~=4.9 (from selenium)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting websocket-client~=1.8 (from selenium)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Collecting cffi>=1.14 (from trio~=0.17->selenium)\n",
      "  Downloading cffi-1.17.1-cp313-cp313-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pycparser (from cffi>=1.14->trio~=0.17->selenium)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.9.0)\n",
      "Using cached selenium-4.26.1-py3-none-any.whl (9.7 MB)\n",
      "Using cached trio-0.27.0-py3-none-any.whl (481 kB)\n",
      "Using cached trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading cffi-1.17.1-cp313-cp313-win_amd64.whl (182 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: sortedcontainers, wsproto, websocket-client, typing_extensions, pysocks, pycparser, attrs, outcome, cffi, trio, trio-websocket, selenium\n",
      "Successfully installed attrs-24.2.0 cffi-1.17.1 outcome-1.3.0.post0 pycparser-2.22 pysocks-1.7.1 selenium-4.26.1 sortedcontainers-2.4.0 trio-0.27.0 trio-websocket-0.11.1 typing_extensions-4.12.2 websocket-client-1.8.0 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting webdriver-manager\n",
      "  Using cached webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Collecting python-dotenv (from webdriver-manager)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\jiann\\appdata\\roaming\\python\\python313\\site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->webdriver-manager) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->webdriver-manager) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->webdriver-manager) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->webdriver-manager) (2024.8.30)\n",
      "Using cached webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-1.0.1 webdriver-manager-4.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"urllib.parse\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.1.2-cp313-cp313-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jiann\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.0-cp313-cp313-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.54.1-cp313-cp313-win_amd64.whl.metadata (167 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp313-cp313-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jiann\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (24.1)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.0.0-cp313-cp313-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jiann\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 6.8/11.5 MB 33.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.5 MB 28.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 26.6 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.9.2-cp313-cp313-win_amd64.whl (7.8 MB)\n",
      "   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 3.7/7.8 MB 19.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.0/7.8 MB 15.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.8/7.8 MB 12.8 MB/s eta 0:00:00\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading contourpy-1.3.0-cp313-cp313-win_amd64.whl (218 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.54.1-cp313-cp313-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 1.0/2.2 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 6.5 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.7-cp313-cp313-win_amd64.whl (55 kB)\n",
      "Downloading numpy-2.1.2-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 7.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.9/12.6 MB 7.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.5/12.6 MB 7.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.8/12.6 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.6 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 9.6 MB/s eta 0:00:00\n",
      "Downloading pillow-11.0.0-cp313-cp313-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 14.4 MB/s eta 0:00:00\n",
      "Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, pyparsing, pillow, numpy, kiwisolver, fonttools, cycler, pandas, contourpy, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.54.1 kiwisolver-1.4.7 matplotlib-3.9.2 numpy-2.1.2 pandas-2.2.3 pillow-11.0.0 pyparsing-3.2.0 pytz-2024.2 seaborn-0.13.2 tzdata-2024.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.1.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.14.1-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scipy-1.14.1-cp313-cp313-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 5.5/44.5 MB 29.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 8.7/44.5 MB 22.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 10.5/44.5 MB 18.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 11.5/44.5 MB 15.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 13.1/44.5 MB 13.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 14.7/44.5 MB 12.0 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 17.3/44.5 MB 11.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 20.2/44.5 MB 12.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 22.8/44.5 MB 12.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 25.2/44.5 MB 12.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 26.5/44.5 MB 11.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 27.5/44.5 MB 11.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 28.8/44.5 MB 10.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.1/44.5 MB 10.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 32.0/44.5 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 33.8/44.5 MB 10.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 35.7/44.5 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.0/44.5 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.3/44.5 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.1/44.5 MB 9.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.9/44.5 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.5 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 9.6 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.5.2-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 7.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.6/11.0 MB 6.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.2/11.0 MB 7.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.2/11.0 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.8/11.0 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.4/11.0 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/11.0 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 7.2 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Requirement already satisfied: selenium in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.26.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade selenium\n",
    "%pip install webdriver-manager\n",
    "%pip urllib.parse\n",
    "%pip install requests beautifulsoup4\n",
    "%pip install pandas matplotlib seaborn\n",
    "%pip install numpy scipy scikit-learn\n",
    "%pip install selenium\n",
    "%pip install tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\jiann\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting retrying\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\users\\jiann\\appdata\\roaming\\python\\python313\\site-packages (from retrying) (1.16.0)\n",
      "Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: retrying\n",
      "Successfully installed retrying-1.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl\n",
    "%pip install retrying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import re\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 7, 5\n",
    "rcParams['font.size'] = 10\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "%matplotlib inline\n",
    "\n",
    "#Data Acquisition\n",
    "import requests                 #How Python gets the webpages\n",
    "from bs4 import BeautifulSoup   #Creates structured, searchable object\n",
    "\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "\n",
    "from selenium import webdriver #Provides an API for controlling web browsers programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from retrying import retry\n",
    "import re\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# 设置日志\n",
    "def setup_logger(listing_id):\n",
    "    # 从URL中提取listing_id\n",
    "    if isinstance(listing_id, str) and 'rooms/' in listing_id:\n",
    "        listing_id = listing_id.split('rooms/')[-1].split('?')[0]\n",
    "    \n",
    "    # 创建logs文件夹（如果不存在）\n",
    "    if not os.path.exists('logs'):\n",
    "        os.makedirs('logs')\n",
    "    \n",
    "    # 设置日志文件名，包含时间戳和listing_id\n",
    "    log_filename = f'logs/airbnb_scraper_{listing_id}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'\n",
    "    \n",
    "    # 配置日志\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_filename),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def select_dates(driver, checkin_date, checkout_date):\n",
    "    logger.info(f\"尝试选择日期: 入住 {checkin_date}, 退房 {checkout_date}\")\n",
    "    \n",
    "    try:\n",
    "        # 等待日历加载\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"_1ncwt1cd\"))\n",
    "        )\n",
    "        \n",
    "        # 查找并点击入住日期\n",
    "        checkin_xpath = f\"//td[@role='button'][@aria-label[contains(., '{checkin_date}')]]\"\n",
    "        checkin_element = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, checkin_xpath))\n",
    "        )\n",
    "        logger.info(\"找到入住日期元素\")\n",
    "        checkin_element.click()\n",
    "        logger.info(\"已点击入住日期\")\n",
    "        \n",
    "        # 等待一下确保日历状态更新\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # 查找并点击退房日期\n",
    "        checkout_xpath = f\"//td[@role='button'][@aria-label[contains(., '{checkout_date}')]]\"\n",
    "        checkout_element = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, checkout_xpath))\n",
    "        )\n",
    "        logger.info(\"找到退房日期元素\")\n",
    "        checkout_element.click()\n",
    "        logger.info(\"已点击退房日期\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"选择日期失败: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(stop_max_attempt_number=3, wait_fixed=2000)\n",
    "\n",
    "\n",
    "def scrape_listing_pricing(listing_url, guests, num_days):\n",
    "\n",
    " # 设置日志\n",
    "    logger = setup_logger(listing_url)\n",
    "    logger.info(f\"开始抓取房源: {listing_url}\")\n",
    "    logger.info(f\"设置: guests={guests}, num_days={num_days}\")\n",
    "\n",
    "    df = pd.DataFrame(columns=[\n",
    "        'Check-in Date', 'Check-out Date', 'Host', \n",
    "        'Guest', 'bedrooms', 'beds', 'baths', 'years_hosting',\n",
    "        'nightly_price', 'cleaning_fee', 'service_fee', 'total',\n",
    "        'availability'\n",
    "    ])\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--disable-gpu')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        logger.info(\"Chrome WebDriver 初始化成功\")\n",
    "\n",
    "        current_date = datetime.now()\n",
    "        end_date = current_date + timedelta(days=num_days)\n",
    "        \n",
    "        # 首先访问页面获取房屋基本信息\n",
    "        url = f\"{listing_url}\"\n",
    "        logger.info(f\"访问页面: {url}\")\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        logger.info(\"页面解析完成\")\n",
    "        \n",
    "        # 获取房屋基本信息\n",
    "        try:\n",
    "            house_elements = soup.findAll(class_='l7n4lsf atm_9s_1o8liyq_keqd55 dir dir-ltr')\n",
    "            logger.info(f\"找到 {len(house_elements)} 个房屋信息元素\")\n",
    "\n",
    "            if house_elements and len(house_elements) >= 5:\n",
    "                def safe_extract_number(text):\n",
    "                    match = re.search(r'\\d+', text)\n",
    "                    return float(match.group()) if match else 'NaN'\n",
    "                \n",
    "                Guests = safe_extract_number(house_elements[0].text)\n",
    "                bedrooms = safe_extract_number(house_elements[1].text)\n",
    "                beds = safe_extract_number(house_elements[2].text)\n",
    "                baths = safe_extract_number(house_elements[3].text)\n",
    "                years_hosting = safe_extract_number(house_elements[4].text)\n",
    "\n",
    "                logger.info(f\"房屋信息: Guests={Guests}, bedrooms={bedrooms}, beds={beds}, \"\n",
    "                          f\"baths={baths}, years_hosting={years_hosting}\")\n",
    "            else:\n",
    "                logger.warning(\"未找到足够的房屋信息元素\")\n",
    "                Guests = bedrooms = beds = baths = years_hosting = 'NaN'\n",
    "        except Exception as e:\n",
    "            logger.error(f\"获取房屋信息出错: {str(e)}\")\n",
    "            Guests = bedrooms = beds = baths = years_hosting = 'NaN'\n",
    "\n",
    "        success_count = 0\n",
    "        fail_count = 0\n",
    "        \n",
    "        while current_date <= end_date:\n",
    "            try:\n",
    "                checkin_date = current_date.strftime('%Y-%m-%d')\n",
    "                checkout_date = (current_date + timedelta(days=2)).strftime('%Y-%m-%d')\n",
    "\n",
    "                logger.info(f\"\\n处理日期: {checkin_date} 到 {checkout_date}\")\n",
    "                \n",
    "                url = f\"{listing_url}?check_in={checkin_date}&guests={guests}&adults={guests}&check_out={checkout_date}\"\n",
    "                driver.get(url)\n",
    "                time.sleep(3)\n",
    "                \n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                \n",
    "                # 检查日期可用性\n",
    "                date_cells = soup.find_all('td', attrs={'role': 'button'})\n",
    "                logger.info(f\"找到 {len(date_cells)} 个日期单元格\")\n",
    "                is_available = True  # 默认可用\n",
    "                \n",
    "                for cell in date_cells:\n",
    "                    date_label = cell.get('aria-label', '')\n",
    "                    if checkin_date in date_label:\n",
    "                        is_available = cell.get('aria-disabled') != 'true'\n",
    "                        logger.info(f\"日期 {checkin_date} 可用性: {'可用' if is_available else '不可用'}\")\n",
    "\n",
    "                        break\n",
    "                \n",
    "                # 如果日期不可用，添加基本信息并跳过价格抓取\n",
    "                if not is_available:\n",
    "                    logger.info(f\"日期 {checkin_date} 不可预订，跳过价格抓取\")\n",
    "                    df = pd.concat([df, pd.DataFrame({\n",
    "                        'Host': [listing_url],\n",
    "                        'Check-in Date': [checkin_date],\n",
    "                        'Check-out Date': [checkout_date],\n",
    "                        'Guest': [Guests],\n",
    "                        'bedrooms': [bedrooms],\n",
    "                        'beds': [beds],\n",
    "                        'baths': [baths],\n",
    "                        'years_hosting': [years_hosting],\n",
    "                        'nightly_price': ['NaN'],\n",
    "                        'cleaning_fee': ['NaN'],\n",
    "                        'service_fee': ['NaN'],\n",
    "                        'total': ['NaN'],\n",
    "                        'availability': ['Unavailable']\n",
    "                    })], ignore_index=True)\n",
    "                    print(f\"{checkin_date} 不可预订，跳过价格抓取\")\n",
    "                    current_date += timedelta(days=1)\n",
    "                    continue\n",
    "                \n",
    "                # 日期可用时抓取价格信息\n",
    "                try:\n",
    "                    scripts = soup.find_all('script', {'type': 'application/json'})\n",
    "                    logger.info(f\"找到 {len(scripts)} 个JSON脚本\")\n",
    "\n",
    "                    pricing_data = {\n",
    "                        \"nightly_price\": 'NaN',\n",
    "                        \"cleaning_fee\": 'NaN',\n",
    "                        \"service_fee\": 'NaN',\n",
    "                        \"total\": 'NaN'\n",
    "                    }\n",
    "                    \n",
    "                    price_found = False\n",
    "                    for script in scripts:\n",
    "                        try:\n",
    "                            data = json.loads(script.string)\n",
    "                            if 'pdp_listing_booking_details' in str(data):\n",
    "                                pricing_module = data.get('pdp_listing_booking_details', {})\n",
    "                                pricing_data[\"nightly_price\"] = pricing_module.get('price', {}).get('rate', {}).get('amount', 'NaN')\n",
    "                                pricing_data[\"cleaning_fee\"] = pricing_module.get('price', {}).get('cleaning_fee', {}).get('amount', 'NaN')\n",
    "                                pricing_data[\"service_fee\"] = pricing_module.get('price', {}).get('service_fee', {}).get('amount', 'NaN')\n",
    "                                pricing_data[\"total\"] = pricing_module.get('price', {}).get('total', {}).get('amount', 'NaN')\n",
    "                                logger.info(f\"价格信息: {pricing_data}\")\n",
    "                                break\n",
    "                        except json.JSONDecodeError:\n",
    "                            continue\n",
    "                    if not price_found:\n",
    "                        logger.warning(\"未找到价格信息\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"提取定价数据时出错: {str(e)}\")\n",
    "                \n",
    "                # 添加可用日期的完整数据\n",
    "                df = pd.concat([df, pd.DataFrame({\n",
    "                    'Host': [listing_url],\n",
    "                    'Check-in Date': [checkin_date],\n",
    "                    'Check-out Date': [checkout_date],\n",
    "                    'Guest': [Guests],\n",
    "                    'bedrooms': [bedrooms],\n",
    "                    'beds': [beds],\n",
    "                    'baths': [baths],\n",
    "                    'years_hosting': [years_hosting],\n",
    "                    'nightly_price': [pricing_data[\"nightly_price\"]],\n",
    "                    'cleaning_fee': [pricing_data[\"cleaning_fee\"]],\n",
    "                    'service_fee': [pricing_data[\"service_fee\"]],\n",
    "                    'total': [pricing_data[\"total\"]],\n",
    "                    'availability': ['Available']\n",
    "                })], ignore_index=True)\n",
    "\n",
    "                success_count += 1\n",
    "                logger.info(f\"成功抓取日期 {checkin_date} 的数据\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                fail_count += 1\n",
    "                logger.error(f\"处理日期 {checkin_date} 时出错: {str(e)}\")\n",
    "                \n",
    "            finally:\n",
    "                current_date += timedelta(days=1)\n",
    "\n",
    "        logger.info(f\"\\n抓取统计:\")\n",
    "        logger.info(f\"总天数: {num_days}\")\n",
    "        logger.info(f\"成功天数: {success_count}\")\n",
    "        logger.info(f\"失败天数: {fail_count}\")\n",
    "        logger.info(f\"成功率: {(success_count/num_days)*100:.2f}%\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        logger.error(f\"抓取过程出错: {str(e)}\")\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()\n",
    "        logger.info(\"浏览器已关闭\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单个网页抓去测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 18:23:15,772 [INFO] 开始抓取房源: https://www.airbnb.co.nz/rooms/837352260137971048\n",
      "2024-11-02 18:23:15,773 [INFO] 设置: guests=3, num_days=10\n",
      "2024-11-02 18:23:15,774 [INFO] ====== WebDriver manager ======\n",
      "2024-11-02 18:23:16,531 [INFO] Get LATEST chromedriver version for google-chrome\n",
      "2024-11-02 18:23:16,786 [INFO] Get LATEST chromedriver version for google-chrome\n",
      "2024-11-02 18:23:16,832 [INFO] Driver [C:\\Users\\jiann\\.wdm\\drivers\\chromedriver\\win64\\130.0.6723.91\\chromedriver-win32/chromedriver.exe] found in cache\n",
      "2024-11-02 18:23:17,974 [INFO] Chrome WebDriver 初始化成功\n",
      "2024-11-02 18:23:17,975 [INFO] 访问页面: https://www.airbnb.co.nz/rooms/837352260137971048\n",
      "2024-11-02 18:23:25,250 [INFO] 页面解析完成\n",
      "2024-11-02 18:23:25,262 [INFO] 找到 6 个房屋信息元素\n",
      "2024-11-02 18:23:25,262 [INFO] 房屋信息: Guests=6.0, bedrooms=3.0, beds=4.0, baths=2.0, years_hosting=NaN\n",
      "2024-11-02 18:23:25,263 [INFO] \n",
      "处理日期: 2024-11-02 到 2024-11-04\n",
      "2024-11-02 18:23:29,325 [INFO] 找到 123 个日期单元格\n",
      "2024-11-02 18:23:29,327 [INFO] 找到 7 个JSON脚本\n",
      "2024-11-02 18:23:29,332 [WARNING] 未找到价格信息\n",
      "C:\\Users\\jiann\\AppData\\Local\\Temp\\ipykernel_26388\\1361362764.py:151: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame({\n",
      "2024-11-02 18:23:29,335 [INFO] 成功抓取日期 2024-11-02 的数据\n",
      "2024-11-02 18:23:29,335 [INFO] \n",
      "处理日期: 2024-11-03 到 2024-11-05\n",
      "2024-11-02 18:23:33,483 [INFO] 找到 123 个日期单元格\n",
      "2024-11-02 18:23:33,487 [INFO] 找到 7 个JSON脚本\n",
      "2024-11-02 18:23:33,492 [WARNING] 未找到价格信息\n",
      "2024-11-02 18:23:33,493 [INFO] 成功抓取日期 2024-11-03 的数据\n",
      "2024-11-02 18:23:33,494 [INFO] \n",
      "处理日期: 2024-11-04 到 2024-11-06\n",
      "2024-11-02 18:23:37,813 [INFO] 找到 123 个日期单元格\n",
      "2024-11-02 18:23:37,815 [INFO] 找到 7 个JSON脚本\n",
      "2024-11-02 18:23:37,820 [WARNING] 未找到价格信息\n",
      "2024-11-02 18:23:37,822 [INFO] 成功抓取日期 2024-11-04 的数据\n",
      "2024-11-02 18:23:37,822 [INFO] \n",
      "处理日期: 2024-11-05 到 2024-11-07\n",
      "2024-11-02 18:23:41,915 [INFO] 找到 123 个日期单元格\n",
      "2024-11-02 18:23:41,917 [INFO] 找到 7 个JSON脚本\n",
      "2024-11-02 18:23:41,923 [WARNING] 未找到价格信息\n",
      "2024-11-02 18:23:41,924 [INFO] 成功抓取日期 2024-11-05 的数据\n",
      "2024-11-02 18:23:41,925 [INFO] \n",
      "处理日期: 2024-11-06 到 2024-11-08\n",
      "2024-11-02 18:23:45,917 [INFO] 找到 123 个日期单元格\n",
      "2024-11-02 18:23:45,919 [INFO] 找到 7 个JSON脚本\n",
      "2024-11-02 18:23:45,925 [WARNING] 未找到价格信息\n",
      "2024-11-02 18:23:45,926 [INFO] 成功抓取日期 2024-11-06 的数据\n",
      "2024-11-02 18:23:45,926 [INFO] \n",
      "处理日期: 2024-11-07 到 2024-11-09\n",
      "2024-11-02 18:23:50,146 [INFO] 找到 123 个日期单元格\n",
      "2024-11-02 18:23:50,148 [INFO] 找到 7 个JSON脚本\n",
      "2024-11-02 18:23:50,153 [WARNING] 未找到价格信息\n",
      "2024-11-02 18:23:50,155 [INFO] 成功抓取日期 2024-11-07 的数据\n",
      "2024-11-02 18:23:50,155 [INFO] \n",
      "处理日期: 2024-11-08 到 2024-11-10\n",
      "2024-11-02 18:23:54,293 [INFO] 找到 123 个日期单元格\n",
      "2024-11-02 18:23:54,295 [INFO] 找到 7 个JSON脚本\n",
      "2024-11-02 18:23:54,300 [WARNING] 未找到价格信息\n",
      "2024-11-02 18:23:54,302 [INFO] 成功抓取日期 2024-11-08 的数据\n",
      "2024-11-02 18:23:54,302 [INFO] \n",
      "处理日期: 2024-11-09 到 2024-11-11\n",
      "2024-11-02 18:23:58,204 [INFO] 找到 123 个日期单元格\n",
      "2024-11-02 18:23:58,206 [INFO] 找到 7 个JSON脚本\n",
      "2024-11-02 18:23:58,211 [WARNING] 未找到价格信息\n",
      "2024-11-02 18:23:58,212 [INFO] 成功抓取日期 2024-11-09 的数据\n",
      "2024-11-02 18:23:58,213 [INFO] \n",
      "处理日期: 2024-11-10 到 2024-11-12\n",
      "2024-11-02 18:24:02,258 [INFO] 找到 123 个日期单元格\n",
      "2024-11-02 18:24:02,260 [INFO] 找到 7 个JSON脚本\n",
      "2024-11-02 18:24:02,265 [WARNING] 未找到价格信息\n",
      "2024-11-02 18:24:02,268 [INFO] 成功抓取日期 2024-11-10 的数据\n",
      "2024-11-02 18:24:02,269 [INFO] \n",
      "处理日期: 2024-11-11 到 2024-11-13\n",
      "2024-11-02 18:24:06,387 [INFO] 找到 123 个日期单元格\n",
      "2024-11-02 18:24:06,389 [INFO] 找到 7 个JSON脚本\n",
      "2024-11-02 18:24:06,394 [WARNING] 未找到价格信息\n",
      "2024-11-02 18:24:06,395 [INFO] 成功抓取日期 2024-11-11 的数据\n",
      "2024-11-02 18:24:06,395 [INFO] \n",
      "处理日期: 2024-11-12 到 2024-11-14\n",
      "2024-11-02 18:24:10,384 [INFO] 找到 123 个日期单元格\n",
      "2024-11-02 18:24:10,386 [INFO] 找到 7 个JSON脚本\n",
      "2024-11-02 18:24:10,391 [WARNING] 未找到价格信息\n",
      "2024-11-02 18:24:10,393 [INFO] 成功抓取日期 2024-11-12 的数据\n",
      "2024-11-02 18:24:10,393 [INFO] \n",
      "抓取统计:\n",
      "2024-11-02 18:24:10,393 [INFO] 总天数: 10\n",
      "2024-11-02 18:24:10,394 [INFO] 成功天数: 11\n",
      "2024-11-02 18:24:10,394 [INFO] 失败天数: 0\n",
      "2024-11-02 18:24:10,394 [INFO] 成功率: 110.00%\n",
      "2024-11-02 18:24:12,539 [INFO] 浏览器已关闭\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Check-in Date</th>\n",
       "      <th>Check-out Date</th>\n",
       "      <th>Host</th>\n",
       "      <th>Guest</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>years_hosting</th>\n",
       "      <th>nightly_price</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>service_fee</th>\n",
       "      <th>total</th>\n",
       "      <th>availability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-02</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>https://www.airbnb.co.nz/rooms/837352260137971048</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>https://www.airbnb.co.nz/rooms/837352260137971048</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>https://www.airbnb.co.nz/rooms/837352260137971048</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>https://www.airbnb.co.nz/rooms/837352260137971048</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>https://www.airbnb.co.nz/rooms/837352260137971048</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>2024-11-09</td>\n",
       "      <td>https://www.airbnb.co.nz/rooms/837352260137971048</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>2024-11-10</td>\n",
       "      <td>https://www.airbnb.co.nz/rooms/837352260137971048</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-11-09</td>\n",
       "      <td>2024-11-11</td>\n",
       "      <td>https://www.airbnb.co.nz/rooms/837352260137971048</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-11-10</td>\n",
       "      <td>2024-11-12</td>\n",
       "      <td>https://www.airbnb.co.nz/rooms/837352260137971048</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-11-11</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>https://www.airbnb.co.nz/rooms/837352260137971048</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-11-12</td>\n",
       "      <td>2024-11-14</td>\n",
       "      <td>https://www.airbnb.co.nz/rooms/837352260137971048</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Check-in Date Check-out Date  \\\n",
       "0     2024-11-02     2024-11-04   \n",
       "1     2024-11-03     2024-11-05   \n",
       "2     2024-11-04     2024-11-06   \n",
       "3     2024-11-05     2024-11-07   \n",
       "4     2024-11-06     2024-11-08   \n",
       "5     2024-11-07     2024-11-09   \n",
       "6     2024-11-08     2024-11-10   \n",
       "7     2024-11-09     2024-11-11   \n",
       "8     2024-11-10     2024-11-12   \n",
       "9     2024-11-11     2024-11-13   \n",
       "10    2024-11-12     2024-11-14   \n",
       "\n",
       "                                                 Host  Guest  bedrooms  beds  \\\n",
       "0   https://www.airbnb.co.nz/rooms/837352260137971048    6.0       3.0   4.0   \n",
       "1   https://www.airbnb.co.nz/rooms/837352260137971048    6.0       3.0   4.0   \n",
       "2   https://www.airbnb.co.nz/rooms/837352260137971048    6.0       3.0   4.0   \n",
       "3   https://www.airbnb.co.nz/rooms/837352260137971048    6.0       3.0   4.0   \n",
       "4   https://www.airbnb.co.nz/rooms/837352260137971048    6.0       3.0   4.0   \n",
       "5   https://www.airbnb.co.nz/rooms/837352260137971048    6.0       3.0   4.0   \n",
       "6   https://www.airbnb.co.nz/rooms/837352260137971048    6.0       3.0   4.0   \n",
       "7   https://www.airbnb.co.nz/rooms/837352260137971048    6.0       3.0   4.0   \n",
       "8   https://www.airbnb.co.nz/rooms/837352260137971048    6.0       3.0   4.0   \n",
       "9   https://www.airbnb.co.nz/rooms/837352260137971048    6.0       3.0   4.0   \n",
       "10  https://www.airbnb.co.nz/rooms/837352260137971048    6.0       3.0   4.0   \n",
       "\n",
       "    baths years_hosting nightly_price cleaning_fee service_fee total  \\\n",
       "0     2.0           NaN           NaN          NaN         NaN   NaN   \n",
       "1     2.0           NaN           NaN          NaN         NaN   NaN   \n",
       "2     2.0           NaN           NaN          NaN         NaN   NaN   \n",
       "3     2.0           NaN           NaN          NaN         NaN   NaN   \n",
       "4     2.0           NaN           NaN          NaN         NaN   NaN   \n",
       "5     2.0           NaN           NaN          NaN         NaN   NaN   \n",
       "6     2.0           NaN           NaN          NaN         NaN   NaN   \n",
       "7     2.0           NaN           NaN          NaN         NaN   NaN   \n",
       "8     2.0           NaN           NaN          NaN         NaN   NaN   \n",
       "9     2.0           NaN           NaN          NaN         NaN   NaN   \n",
       "10    2.0           NaN           NaN          NaN         NaN   NaN   \n",
       "\n",
       "   availability  \n",
       "0     Available  \n",
       "1     Available  \n",
       "2     Available  \n",
       "3     Available  \n",
       "4     Available  \n",
       "5     Available  \n",
       "6     Available  \n",
       "7     Available  \n",
       "8     Available  \n",
       "9     Available  \n",
       "10    Available  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example URL and parameters\n",
    "listing_url = 'https://www.airbnb.co.nz/rooms/837352260137971048'\n",
    "guests = 3\n",
    "num_days = 10 #change to 180 for 6 Months\n",
    "\n",
    "#Scrape pricing data for the next 180 days\n",
    "pricing_data = scrape_listing_pricing(listing_url, guests, num_days)\n",
    "\n",
    "pricing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自动多网页抓取测试\n",
    "#### 网页选择器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "urls = [\n",
    "'https://www.airbnb.co.nz/rooms/49525122',\n",
    "'https://www.airbnb.co.nz/rooms/49525472',\n",
    "'https://www.airbnb.co.nz/rooms/716883705085875481',\n",
    "'https://www.airbnb.co.nz/rooms/1044551981539410265',\n",
    "'https://www.airbnb.co.nz/rooms/635947170438929163',\n",
    "'https://www.airbnb.co.nz/rooms/1044551981539410265',\n",
    "'https://www.airbnb.co.nz/rooms/668902191198356462',\n",
    "'https://www.airbnb.co.nz/rooms/38854776',\n",
    "'https://www.airbnb.co.nz/rooms/856174211238380149',\n",
    "'https://www.airbnb.co.nz/rooms/676112692890991678',\n",
    "'https://www.airbnb.co.nz/rooms/769112025086830655',\n",
    "'https://www.airbnb.co.nz/rooms/668902191198356462',\n",
    "'https://www.airbnb.co.nz/rooms/709166860198621755',\n",
    "'https://www.airbnb.co.nz/rooms/818542484636231684',\n",
    "'https://www.airbnb.co.nz/rooms/837352260137971048',\n",
    "'https://www.airbnb.co.nz/rooms/54370426',\n",
    "'https://www.airbnb.co.nz/rooms/18348257',\n",
    "'https://www.airbnb.co.nz/rooms/648591357028974926',\n",
    "'https://www.airbnb.co.nz/rooms/669791209041202721',\n",
    "'https://www.airbnb.co.nz/rooms/976482042592323453',\n",
    "'https://www.airbnb.co.nz/rooms/969823904189469776',\n",
    "'https://www.airbnb.co.nz/rooms/814639112400706392',\n",
    "'https://www.airbnb.co.nz/rooms/1039583273388527380',\n",
    "    \n",
    "]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(urls, columns=['URL'])\n",
    "\n",
    "# Export to Excel\n",
    "df.to_excel('urls.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel('urls.xlsx')\n",
    "\n",
    "# The number of guests and days\n",
    "guests = 3       #选择入住人数\n",
    "num_days = 180  #选择抓去的天数\n",
    "\n",
    "# Loop over each URL\n",
    "for listing_url in df['URL']:\n",
    "    print(listing_url)\n",
    "\n",
    "    pricing_data = scrape_listing_pricing(listing_url, guests, num_days)\n",
    "    \n",
    "pricing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_data.to_excel('pricing_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
